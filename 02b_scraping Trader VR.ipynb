{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape cars on sale on various trader websites\n",
    "\n",
    "Approach is different for this one. All of the trader's car can be listed on one page. I've simply loaded the entire page and saved it, with picture files. This is what I'm parsing. \n",
    "\n",
    "This could be set up to be done on a regular basis to identify new cars, sold cars, and so on. \n",
    "\n",
    "Ran this script on:\n",
    "* 09/12/2016\n",
    "* 09/15/2016\n",
    "* 09/16/2016\n",
    "* 09/18/2016\n",
    "\n",
    "Issues:\n",
    "* Need to fix Alfa --> Alfa Romeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import time\n",
    "\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas=True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to dbs\n",
    "conn = sqlite3.connect('data/sales.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = 'www.vroom.com'\n",
    "trader = 'http://www.vroom.com/catalog'\n",
    "browser = webdriver.Chrome()\n",
    "browser.get(trader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2386\n"
     ]
    }
   ],
   "source": [
    "#First get total number of listing today\n",
    "# Will scroll down until we get that number of results\n",
    "soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "num_results = int(soup.find_all(\"div\", class_=\"results\")[0].text.split()[0].replace(',',''))\n",
    "print(num_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876\n",
      "1551\n",
      "2151\n",
      "2387\n"
     ]
    }
   ],
   "source": [
    "# Scroll down the page until entire catalog (num_results) is loaded.\n",
    "# Sometimes the site becomes unresponsive so set num_iter to stop it after a while.\n",
    "num_iter = 0\n",
    "num_cars = 0\n",
    "while num_cars < num_results - 5 and num_iter < 10:\n",
    "    for x in range(0,50):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.random()*.5)\n",
    "\n",
    "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "    cars = soup.find_all(\"div\", class_=\"car-new\")\n",
    "    # carsSP = soup.find_all(\"div\", class_=\"car-new is-sale-pending\")\n",
    "    num_cars = len(cars)# + len(carsSP)\n",
    "    print(num_cars)\n",
    "    num_iter = num_iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parse info\n",
    "all_cars = pd.DataFrame()\n",
    "date = '2016-09-18'\n",
    "\n",
    "# soup = BeautifulSoup(open('./data/VR_scrape/VR09122016.html'),\"lxml\")\n",
    "# cars = soup.find_all(\"div\", class_=\"car-new\")\n",
    "\n",
    "for car in cars:\n",
    "    try:\n",
    "        name = car.find_all(\"div\", class_=\"info\")[0].find_all(\"div\", class_=\"name\")[0].text.split()\n",
    "        if name[1] == 'Land' and name[2] == 'Rover':\n",
    "            year,make,model = name[0],' '.join(name[1:3]),' '.join(name[3:])\n",
    "#             print(make,model)\n",
    "        else:\n",
    "            year,make,model = name[0],name[1],' '.join(name[2:])\n",
    "        trim = car.find_all(\"div\", class_=\"trim\")[0].text\n",
    "        mileage = int(car.find_all(\"div\", class_=\"mileage\")[0].text.replace(',','').replace(' Miles',''))\n",
    "        price = int(car.find_all(\"div\", class_=\"price\")[0].text.replace('$','').replace(',',''))\n",
    "        img_file = car.find_all(\"img\")[0]['src']\n",
    "        all_cars = all_cars.append(pd.DataFrame(\n",
    "            [[date, 'Used',year, make,model,trim,mileage,price,img_file,source]]),\n",
    "                                      ignore_index = True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add to sqlite table salesVR\n",
    "\n",
    "all_cars.columns = ['date','new_used', 'year', 'make', 'model','trim', 'mileage', 'price', 'img_file', 'source']    \n",
    "index_max = conn.execute('SELECT MAX(line_id) FROM salesVR').fetchall()\n",
    "if index_max[0][0] is not None:\n",
    "    all_cars.index = all_cars.index + 1 + index_max[0][0]\n",
    "all_cars.to_sql('salesVR',conn,flavor='sqlite',if_exists='append',index_label='line_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
